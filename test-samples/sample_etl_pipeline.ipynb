{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Sample ETL Pipeline - User Activity Analysis\nThis notebook demonstrates a typical PySpark ETL pipeline."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, count, sum as spark_sum, avg, when, broadcast\nfrom pyspark.sql.window import Window\n\nspark = SparkSession.builder \\\n    .appName('UserActivityETL') \\\n    .config('spark.sql.shuffle.partitions', '200') \\\n    .getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Read raw event logs from S3\nevents_df = spark.read.parquet('s3://data-lake/raw/events/')\nusers_df = spark.read.parquet('s3://data-lake/raw/users/')\nproducts_df = spark.read.csv('s3://data-lake/raw/products.csv', header=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter to last 30 days and remove bots\nclean_events = events_df \\\n    .filter(col('event_date') >= '2025-01-01') \\\n    .filter(col('is_bot') == False) \\\n    .dropDuplicates(['event_id'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Join events with user data (potential skew on popular users)\nenriched = clean_events.join(users_df, 'user_id', 'left') \\\n    .join(broadcast(products_df), 'product_id', 'left')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Aggregate by user - causes shuffle\nuser_summary = enriched.groupBy('user_id', 'country') \\\n    .agg(\n        count('event_id').alias('total_events'),\n        spark_sum(when(col('event_type') == 'purchase', col('amount'))).alias('total_spend'),\n        avg('session_duration').alias('avg_session')\n    )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Window function for ranking\nfrom pyspark.sql.functions import row_number\nwindow_spec = Window.partitionBy('country').orderBy(col('total_spend').desc())\nranked = user_summary.withColumn('rank', row_number().over(window_spec))\n\n# Get top 100 spenders per country\ntop_spenders = ranked.filter(col('rank') <= 100)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write results\ntop_spenders.write \\\n    .mode('overwrite') \\\n    .partitionBy('country') \\\n    .parquet('s3://data-lake/curated/top_spenders/')\n\nprint(f'Wrote {top_spenders.count()} records')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.0"}},"nbformat":4,"nbformat_minor":4}
